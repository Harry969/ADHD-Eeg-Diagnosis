{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Retrieve the total matrix of standardized data**: \n",
    "   - The data matrix is called `total_list_stand`.\n",
    "\n",
    "2. **Test with a sample of the matrix to apply XGBoost**: \n",
    "   - We will use a small sample from the standardized matrix to perform initial testing with XGBoost.\n",
    "\n",
    "3. **Plot the feature importance based on XGBoost**: \n",
    "   - After training the XGBoost model, we will visualize the importance of each feature according to the model.\n",
    "\n",
    "4. **Run a loop over the matrices to apply XGBoost with Cross-Validation (CV) to all extracted matrices**:\n",
    "   - We will iterate over all the data matrices and apply XGBoost with cross-validation to find the best parameters.\n",
    "\n",
    "5. **Store results in `list_result`**: \n",
    "   - For each iteration, store the following tuple of data in `list_result`: \n",
    "      - `(prep, troz, chan, eta, gamma, max_depth, acc, std_error)`.\n",
    "\n",
    "6. **Create a DataFrame to better view and sort the results**: \n",
    "   - Convert the `list_result` into a DataFrame for easy viewing and sorting of the results.\n",
    "\n",
    "7. **Train the final model with the best combination from the CV and test it by plotting the confusion matrix**:\n",
    "   - Using the best hyperparameters from cross-validation, train a final XGBoost model, test it, and visualize the confusion matrix (~0.8 Accuracy).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the total_list_stand from the saved file\n",
    "with open('total_list_stand.pkl', 'rb') as f:\n",
    "    total_list_stand = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, `total_list_stand` contains 4 lists, each corresponding to one of the preprocessing methods. \n",
    "\n",
    "Each of these 4 lists contains 35 sublists, representing the different segments (chunks) that we have generated. \n",
    "\n",
    "In turn, each of these 35 sublists contains 19 matrices of size 121x54, one for each EEG channel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_channel(num):\n",
    "    # Mapping of numbers to channel names\n",
    "    channel_map = {\n",
    "        0: 'Fp1', 1: 'Fp2', 2: 'F3', 3: 'F4', 4: 'C3', 5: 'C4', 6: 'P3',\n",
    "        7: 'P4', 8: 'O1', 9: 'O2', 10: 'F7', 11: 'F8', 12: 'T7', 13: 'T8',\n",
    "        14: 'P7', 15: 'P8', 16: 'Fz', 17: 'Cz', 18: 'Pz'\n",
    "    }\n",
    "\n",
    "    # Return the channel name if the number exists, otherwise return an error message\n",
    "    return channel_map.get(num, 'Channel error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "list_results = []\n",
    "\n",
    "# Iterate through preprocessing types (you may expand this loop if needed)\n",
    "for prep in range(4):  # Assuming you're only running for the first preprocessing type\n",
    "    for segment in range(35):  # Loop over the different segments (chunks)\n",
    "        for channel in range(19):  # Iterate over all 19 EEG channels\n",
    "            print(f'Processing: prep={prep}, segment={segment}, channel={channel}')\n",
    "\n",
    "            # Retrieve the standardized data for the given preprocessing, segment, and channel\n",
    "            df_data = total_list_stand[prep][segment][channel]\n",
    "\n",
    "            # Convert the data to numpy arrays (features and labels)\n",
    "            features = df_data.iloc[:, :-1].to_numpy()  # All columns except the last (features)\n",
    "            labels = df_data['Label'].to_numpy()  # The last column (labels)\n",
    "\n",
    "            # Convert the data to XGBoost's DMatrix format for efficient processing\n",
    "            dtrain = xgb.DMatrix(features, label=labels)\n",
    "\n",
    "            # Define the hyperparameters for XGBoost\n",
    "            eta_values = [0.01, 0.1, 0.5, 1]  # Learning rates\n",
    "            gamma_values = [0, 1]  # Minimum loss reduction\n",
    "            max_depth_values = [2, 3, 6, 12, 24]  # Maximum tree depth\n",
    "\n",
    "            # Loop over the hyperparameter combinations\n",
    "            for eta in eta_values:\n",
    "                for gamma in gamma_values:\n",
    "                    for max_depth in max_depth_values:\n",
    "                        # Set the XGBoost parameters\n",
    "                        params = {\n",
    "                            \"max_depth\": max_depth,\n",
    "                            \"eta\": eta,\n",
    "                            \"gamma\": gamma,\n",
    "                            \"objective\": \"binary:logistic\"  # Binary classification task\n",
    "                        }\n",
    "                        num_rounds = 30  # Number of boosting rounds\n",
    "                        k_folds = StratifiedKFold(n_splits=5)  # 5-fold stratified cross-validation\n",
    "\n",
    "                        # Perform cross-validation using XGBoost\n",
    "                        res = xgb.cv(\n",
    "                            params,\n",
    "                            dtrain,\n",
    "                            num_boost_round=num_rounds,\n",
    "                            folds=k_folds,\n",
    "                            stratified=True,\n",
    "                            metrics={\"error\"},\n",
    "                            seed=1,\n",
    "                            verbose_eval=False  # Set to False to suppress output during CV\n",
    "                        )\n",
    "\n",
    "                        # Extract the best result (min test error)\n",
    "                        best_result = res.loc[res['test-error-mean'].idxmin()]\n",
    "                        min_error = round(best_result['test-error-mean'], 4)  # Minimum error\n",
    "                        std_error = round(best_result['test-error-std'], 4)  # Standard deviation of the error\n",
    "\n",
    "                        # Convert the channel number to its corresponding name\n",
    "                        channel_name = num_to_channel(channel)\n",
    "\n",
    "                        # Append the results as a tuple\n",
    "                        list_results.append((prep, segment, channel_name, eta, gamma, max_depth, 1 - min_error, std_error))\n",
    "\n",
    "                        # Optional: Print the result\n",
    "                        print(f'Accuracy: {1 - min_error} Â± {std_error} for {channel_name}, eta={eta}, gamma={gamma}, max_depth={max_depth}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort results by accuracy (index 6) in descending order\n",
    "list_results.sort(key=lambda x: x[6], reverse=True)\n",
    "\n",
    "# Create a DataFrame from the sorted results\n",
    "df_results_xgb = pd.DataFrame(\n",
    "    list_results, \n",
    "    columns=['Preprocess', 'Segment', 'Channel', 'Eta', 'Gamma', 'max_depth', 'Accuracy', 'Std_error']\n",
    ")\n",
    "\n",
    "# Add classifier and feature set information\n",
    "df_results_xgb['clf'] = ['xgboost'] * df_results_xgb.shape[0]\n",
    "df_results_xgb['Features'] = ['all'] * df_results_xgb.shape[0]\n",
    "\n",
    "# Display the top 20 results\n",
    "df_results_xgb.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"xgboost_1channel_df_results.pkl\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(df_results_xgb, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Select the specific data matrix for training and testing\n",
    "df_best_xgb = total_list_stand[0][28][6]\n",
    "\n",
    "# Extract features and labels from the data\n",
    "data = df_best_xgb.iloc[:, :-1].to_numpy()  # Features (all columns except the last)\n",
    "label = df_best_xgb['Label'].to_numpy()  # Labels (last column)\n",
    "\n",
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, train_size=0.8, random_state=12, stratify=label)\n",
    "\n",
    "# Create an instance of the XGBoost classifier with specified parameters\n",
    "model = XGBClassifier(max_depth=3, eta=0.1, gamma=1, objective='binary:logistic')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "features-eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
