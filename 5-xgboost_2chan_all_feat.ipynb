{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We retrieve the total matrix of standarized data: `total_list_stand`.\n",
    "- We generate matrices by pairing EEG channels and concatenate them.\n",
    "- We apply XGBoost with different hyperparameters (eta, gamma, max_depth) using Cross-Validation (CV).\n",
    "- We sort and store the results in a DataFrame for better visualization.\n",
    "- We take the best hyperparameter combination, train an XGBoost model using the training set, and test it on the test set.\n",
    "- We compute and display the confusion matrix to evaluate the modelâ€™s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved list from a pickle file\n",
    "with open(\"total_list_stand.pkl\", \"rb\") as list_tot_stand:\n",
    "    total_list_stand = pickle.load(list_tot_stand)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, `lista_total_stand` contains 4 lists, each corresponding to one of the preprocessing steps.\n",
    "Each of the 4 lists contains 35 sublists, representing the different segments (chunks) we have generated.\n",
    "Furthermore, each of the 35 sublists contains 19 matrices of size 121x54, one for each EEG channel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to take these final matrices and combine them in pairs of channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista_total_stand: Contains the EEG data matrices\n",
    "# Outer loop for each preprocessing method\n",
    "preprocess_list = []\n",
    "for list_prep in total_list_stand:\n",
    "    segments_list = []\n",
    "    \n",
    "    # Loop for each segment\n",
    "    for segment_list in list_prep:\n",
    "        matrix_list = []\n",
    "        \n",
    "        # Nested loops to combine pairs of matrices (channels)\n",
    "        for i in range(len(segment_list)):\n",
    "            for j in range(len(segment_list)):\n",
    "                if j > i:\n",
    "                    # Get the label\n",
    "                    label = segment_list[i]['Label']\n",
    "                    \n",
    "                    # Extract data (without labels) from the two matrices\n",
    "                    df1 = segment_list[i].iloc[:, :-1]\n",
    "                    df2 = segment_list[j].iloc[:, :-1]\n",
    "                    \n",
    "                    # Concatenate the two matrices column-wise\n",
    "                    df3 = pd.concat([df1, df2], axis=1)\n",
    "                    \n",
    "                    # Add the label back to the combined matrix\n",
    "                    df3['Label'] = label\n",
    "                    \n",
    "                    # Append the resulting matrix to the list\n",
    "                    matrix_list.append(df3)\n",
    "        \n",
    "        # Append the matrices for this chunk to the list\n",
    "        segments_list.append(matrix_list)\n",
    "    \n",
    "    # Append the results for this preprocessing method\n",
    "    preprocess_list.append(segments_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in the list `preprocess_list`, we have all the matrices paired by channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store results for each hyperparameter combination\n",
    "results_list = []\n",
    "\n",
    "# Loop through preprocessing methods, segments, and channel pairs\n",
    "for prep in range(4):  # 4 preprocessing types\n",
    "    for segment in range(35):  # 35 segments\n",
    "        for chan in range(171):  # 171 channel pairs\n",
    "            for eta in [0.01, 0.1, 0.5, 1]:  # Learning rates\n",
    "                for gamma in [0, 1]:  # Gamma values\n",
    "                    for max_depth in [2, 3, 6, 12, 24]:  # Max tree depth\n",
    "                        print(f'prep: {prep}, segment: {segment}, chan: {chan}, eta: {eta}, gamma: {gamma}, max_depth: {max_depth}')\n",
    "                        \n",
    "                        # Retrieve the data for this specific combination\n",
    "                        df_data = preprocess_list[prep][segment][chan]\n",
    "                        \n",
    "                        # Convert to numpy arrays (data and labels)\n",
    "                        data_dm = df_data.iloc[:, :-1].to_numpy()  # Features\n",
    "                        label_dm = df_data['Label'].to_numpy()  # Labels\n",
    "                        \n",
    "                        # Convert data into XGBoost DMatrix\n",
    "                        dtrain = xgb.DMatrix(data_dm, label=label_dm)\n",
    "                        \n",
    "                        # Define XGBoost parameters\n",
    "                        param = {\"max_depth\": max_depth, \"eta\": eta, \"gamma\": gamma, \"objective\": \"binary:logistic\"}\n",
    "                        num_round = 30  # Number of boosting rounds\n",
    "                        k_folds = StratifiedKFold(n_splits=5)  # 5-fold stratified cross-validation\n",
    "                        \n",
    "                        # Perform cross-validation\n",
    "                        res = xgb.cv(\n",
    "                            param, dtrain, num_round,\n",
    "                            stratified=True, folds=k_folds,\n",
    "                            metrics={\"error\"}, seed=0, verbose_eval=0\n",
    "                        )\n",
    "                        \n",
    "                        # Extract the best result (minimum test error)\n",
    "                        min_row = res[res['test-error-mean'] == res['test-error-mean'].min()].iloc[0, :]\n",
    "                        min_error = round(min_row['test-error-mean'], 4)\n",
    "                        std_error = round(min_row['test-error-std'], 4)\n",
    "                        \n",
    "                        # Store the results\n",
    "                        results_list.append((prep, segment, chan, eta, gamma, max_depth, 1 - min_error, std_error))\n",
    "                        print('Maximum accuracy obtained:', 1 - min_error, '+-', std_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the results by accuracy (index 6) in descending order\n",
    "results_list.sort(key=lambda x: x[6], reverse=True)\n",
    "\n",
    "# Convert the sorted results into a DataFrame\n",
    "df_results_xgboost = pd.DataFrame(\n",
    "    results_list, \n",
    "    columns=['preprocess', 'segment', 'channel', 'eta', 'gamma', 'max_depth', 'accuracy', 'std_error']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_channels(num):\n",
    "    \"\"\"\n",
    "    Convert a numerical index to a pair of EEG channel names.\n",
    "    \"\"\"\n",
    "    n_channels = 19  # Total number of channels\n",
    "    total_pairs = n_channels * (n_channels - 1) // 2  # Total unique channel pairs\n",
    "\n",
    "    if num < 0 or num >= total_pairs:\n",
    "        return 'Invalid number'\n",
    "\n",
    "    # Calculate the indices of the channel pair\n",
    "    count = 0\n",
    "    for i in range(n_channels - 1):\n",
    "        num_pairs = n_channels - i - 1\n",
    "        if num < count + num_pairs:\n",
    "            j = i + (num - count) + 1\n",
    "            channel_one = num_to_channel(i)\n",
    "            channel_two = num_to_channel(j)\n",
    "            return channel_one, channel_two\n",
    "        count += num_pairs\n",
    "\n",
    "    return 'Invalid number'\n",
    "\n",
    "def num_to_channel(index):\n",
    "    \"\"\"\n",
    "    Map a channel index to its corresponding channel name.\n",
    "    \"\"\"\n",
    "    channel_map = {\n",
    "        0: 'Fp1', 1: 'Fp2', 2: 'F3', 3: 'F4', 4: 'C3', 5: 'C4',\n",
    "        6: 'P3', 7: 'P4', 8: 'O1', 9: 'O2', 10: 'F7', 11: 'F8',\n",
    "        12: 'T7', 13: 'T8', 14: 'P7', 15: 'P8', 16: 'Fz', 17: 'Cz', 18: 'Pz'\n",
    "    }\n",
    "    return channel_map.get(index, 'Unknown channel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the channel numbers to pairs of channel names using num_to_channels\n",
    "list_channel = list(df_results_xgboost['channel'])  # Extract the 'channel' column as a list\n",
    "list_pairs = [num_to_channels(i) for i in list_channel]  # Convert each numerical index to a pair of channels\n",
    "df_results_xgboost['channel'] = list_pairs  # Update the 'channel' column with the channel pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 50 rows of the DataFrame\n",
    "df_results_xgboost.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the DataFrame df_results_xgboost to a pickle file\n",
    "# with open(\"xgboost_2channels_df_results.pkl\", \"wb\") as fp:\n",
    "#     pickle.dump(df_results_xgboost, fp)\n",
    "\n",
    "# # Load the DataFrame df_results_xgboost from the pickle file\n",
    "# with open(\"xgboost_2channels_df_results.pkl\", \"rb\") as df_res_xgboost:\n",
    "#     df_results_xgboost = pickle.load(df_res_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 61 is the number of the list of pairs of channels that corresponds to (F4, P7)\n",
    "num_to_channels(61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the specific data (preprocessing=0, segment=31, channel=61)\n",
    "df_best_xgb = preprocess_list[0][31][61]\n",
    "\n",
    "# Extract features (data) and labels from the DataFrame\n",
    "data = df_best_xgb.iloc[:, :-1].to_numpy()  # Features (all columns except the last)\n",
    "label = df_best_xgb['Label'].to_numpy()  # Labels (last column)\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, train_size=0.8, random_state=4, stratify=label)\n",
    "\n",
    "# Create an instance of the XGBoost best classifier with specified hyperparameters\n",
    "bst = XGBClassifier(max_depth=2, eta=0.1, gamma=0, objective='binary:logistic')\n",
    "\n",
    "# Train the model on the training data\n",
    "bst.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "preds = bst.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the confusion matrix based on true labels and predictions\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "\n",
    "# Plot and display the confusion matrix\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "features-eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
